---
title: "Confidence and Uncertainty"
subtitle: "Homework 8"
author: "Prof. Weldzius"
institute: "Villanova University"
date: 2025-07-24
Due_Date: "2026-06-02 by 11:59PM"
output: html_document
---



<div id="motivation-how-much-do-turnovers-matter" class="section level2">
<h2>Motivation: How much do turnovers matter?</h2>
<p>We’re going to work with a different dataset covering every NBA game played in the seasons 2016-17 to 2018-19. I’m interested in whether winning teams have higher or lower values of turnovers, and whether winning teams tend to more often make over 80 percent of their free throws.</p>
<pre class="r"><code>library(tidyverse)</code></pre>
</div>
<div id="the-data" class="section level2">
<h2>The Data</h2>
<p>The data for today is game by team summary data for every game played from 2017 to 2019. Make sure to download the data (<a href="https://github.com/rweldzius/PSC4175_SUM2025/raw/main/Data/game_summary.Rds">game_summary.Rds</a>) and save to your <code>data</code> folder!</p>
<pre class="r"><code>gms&lt;-read_rds(&quot;../../static/data/game_summary.Rds&quot;)
gms</code></pre>
<pre><code>## # A tibble: 7,380 × 16
##      idGame yearSeason dateGame   idTeam nameTeam locationGame   tov   pts  treb
##       &lt;dbl&gt;      &lt;int&gt; &lt;date&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 21600001       2017 2016-10-25 1.61e9 Clevela… H               14   117    51
##  2 21600001       2017 2016-10-25 1.61e9 New Yor… A               18    88    42
##  3 21600002       2017 2016-10-25 1.61e9 Portlan… H               12   113    34
##  4 21600002       2017 2016-10-25 1.61e9 Utah Ja… A               11   104    31
##  5 21600003       2017 2016-10-25 1.61e9 Golden … H               16   100    35
##  6 21600003       2017 2016-10-25 1.61e9 San Ant… A               13   129    55
##  7 21600004       2017 2016-10-26 1.61e9 Miami H… A               10   108    52
##  8 21600004       2017 2016-10-26 1.61e9 Orlando… H               11    96    45
##  9 21600005       2017 2016-10-26 1.61e9 Dallas … A               15   121    49
## 10 21600005       2017 2016-10-26 1.61e9 Indiana… H               16   130    52
## # ℹ 7,370 more rows
## # ℹ 7 more variables: oreb &lt;dbl&gt;, pctFG &lt;dbl&gt;, pctFT &lt;dbl&gt;, teamrest &lt;dbl&gt;,
## #   second_game &lt;lgl&gt;, isWin &lt;lgl&gt;, ft_80 &lt;dbl&gt;</code></pre>
<p>The codebook for this dataset is as follows:</p>
<table>
<thead>
<tr class="header">
<th>Name</th>
<th align="right">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>idGame</td>
<td align="right">Unique game id</td>
</tr>
<tr class="even">
<td>yearSeason</td>
<td align="right">Which season? NBA uses ending year so 2016-17 = 2017</td>
</tr>
<tr class="odd">
<td>dateGame</td>
<td align="right">Date of the game</td>
</tr>
<tr class="even">
<td>idTeam</td>
<td align="right">Unique team id</td>
</tr>
<tr class="odd">
<td>nameTeam</td>
<td align="right">Team Name</td>
</tr>
<tr class="even">
<td>locationGame</td>
<td align="right">Game location, H=Home, A=Away</td>
</tr>
<tr class="odd">
<td>tov</td>
<td align="right">Total turnovers</td>
</tr>
<tr class="even">
<td>pts</td>
<td align="right">Total points</td>
</tr>
<tr class="odd">
<td>treb</td>
<td align="right">Total rebounds</td>
</tr>
<tr class="even">
<td>pctFG</td>
<td align="right">Field Goal Percentage</td>
</tr>
<tr class="odd">
<td>teamrest</td>
<td align="right">How many days since last game for team</td>
</tr>
<tr class="even">
<td>pctFT</td>
<td align="right">Free throw percentage</td>
</tr>
<tr class="odd">
<td>isWin</td>
<td align="right">Won? TRUE or FALSE</td>
</tr>
<tr class="even">
<td>ft_80</td>
<td align="right">Team scored more than 80 percent of free throws</td>
</tr>
</tbody>
</table>
<p>We’re interested in knowing about how turnovers <code>tov</code> are different between game winners <code>isWin</code>.</p>
</div>
<div id="continuous-variables-point-estimates" class="section level2">
<h2>Continuous Variables: Point Estimates</h2>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2017)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        13.8
## 2 TRUE         12.9</code></pre>
<p>It looks like there’s a fairly substantial difference– winning teams turned the ball over an average of 12.9 times, while losing teams turned it over an average of 13.8 times. One way to summarize this is that winning teams in general had one less turnover per game than losing teams.</p>
<p>What if we take these results and decide that these will apply in other seasons? We could say something like: “Winning teams over the course of a season will turn the ball over 12.9 times, and losing teams 13.8 times, period.” Well let’s look and see:</p>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2018)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        14.1
## 2 TRUE         13.3</code></pre>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2019)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        13.9
## 2 TRUE         13.1</code></pre>
<p>So, no, that’s not right. In other seasons winning teams turned the ball over less, but it’s not as simple as just saying it will always be the two numbers we calculated from the 2017 data.</p>
<p>What we’d like to be able to do is make a more general statement, not just about a given season but about what we can expect in general. To do that we need to provide some kind of range of uncertainty: what range of turnovers can we expect to see from both winning and losing teams? To do that we’re going to use some key insights from probability theory and statistics that help us generate estimates of uncertainty.</p>
<p><strong>Quick exercise</strong> Are winning teams in 2017 more likely to make more than 80 percent of their free throws?*</p>
<pre class="r"><code>gms%&gt;%
  filter(...)%&gt;%
  group_by(...elt())%&gt;%
  summarize(mean(...))</code></pre>
<pre><code>## Error in group_by(., ...elt()): &#39;...&#39; used in an incorrect context</code></pre>
</div>
<div id="sampling" class="section level2">
<h2>Sampling</h2>
<p>We’re going to start by building up a range of uncertainty from the data we already have. We’ll do this by sampling from the data itself.</p>
<p>Let’s just take very small sample of games– 100 games– and calculate turnovers for winners and losers. We are going to <code>set.seed</code> to ensure that we get the same/similar answers every time we run the “random number” generator.</p>
<pre class="r"><code>set.seed(210916)
sample_size&lt;-100
gms%&gt;%
  filter(yearSeason==2017)%&gt;% ## Filter to just 2017
  sample_n(size=sample_size, replace=TRUE) %&gt;% ## Sample size is as set above.  Replacement is set to TRUE
  group_by(isWin)%&gt;% ## Group by win/lose
  summarize(mean(tov)) ## calculate mean</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        14.7
## 2 TRUE         12.9</code></pre>
</div>
<div id="and-again" class="section level2">
<h2>And again:</h2>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2017)%&gt;% ## Filter to just 2017
  sample_n(size=sample_size, replace=TRUE) %&gt;% ## Sample size is as set above
  group_by(isWin)%&gt;% ## Group by win/lose
  summarize(mean(tov)) ## calculate mean</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        14.1
## 2 TRUE         13</code></pre>
<p>Sometimes we can get samples where the winning team turned the ball over more! These reasmples on their own don’t appear to be particularly useful, but what would happen if we calculated a bunch (technical term) of them?</p>
<p>I can continue this process of sampling and generating values many times using a loop. The code below resamples from the data 1,000 times, each time calculating the mean turnovers for winners and losers in a sample of size 10. It then adds those two means to a growing list, using the bind_rows function.
## Warning: the code below will take a little while to run</p>
<pre class="r"><code>gms_tov_rs&lt;-NULL ##  Create a NULL variable: will fill this in later
for (i in 1:1000){ # Repeat the steps below 1000 times
  gms_tov_rs&lt;-gms%&gt;% ## Create a dataset called gms_tov_rs (rs=resampled)
  filter(yearSeason==2017)%&gt;%  ## Just 2017
  sample_n(size=sample_size, replace=TRUE) %&gt;% ## Sample 100 games
  group_by(isWin)%&gt;% ## Group by won or lost
  summarize(mean_tov=mean(tov))%&gt;% ## Calculate mean turnovers for winners and losers
    bind_rows(gms_tov_rs) ## add this result to the existing dataset
}</code></pre>
<p>Now I have a dataset that is built up from a bunch of small resamples from the data, with average turnovers for winners and losers in each small sample. Let’s see what these look like.</p>
<pre class="r"><code>gms_tov_rs</code></pre>
<pre><code>## # A tibble: 2,000 × 2
##    isWin mean_tov
##    &lt;lgl&gt;    &lt;dbl&gt;
##  1 FALSE     14.5
##  2 TRUE      13.7
##  3 FALSE     13.7
##  4 TRUE      12.8
##  5 FALSE     14.4
##  6 TRUE      12.3
##  7 FALSE     13.6
##  8 TRUE      13.2
##  9 FALSE     13.6
## 10 TRUE      11.4
## # ℹ 1,990 more rows</code></pre>
<p>This is a dataset that’s just a bunch of means. We can calculate the mean of all of these means and see what it looks like:</p>
<pre class="r"><code>gms_tov_rs%&gt;%
  group_by(isWin)%&gt;%
  summarise(mean_of_means=mean(mean_tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin mean_of_means
##   &lt;lgl&gt;         &lt;dbl&gt;
## 1 FALSE          13.8
## 2 TRUE           12.9</code></pre>
<p>How does this “mean of means” compare with the actual?</p>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2017)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        13.8
## 2 TRUE         12.9</code></pre>
<p>Pretty similar! It’s what we would expect, really, but it’s super important. If we repeatedly sample from a dataset, our summary measures of a sufficiently large number of repeated samples will converge on the true value of the measure from the dataset.</p>
<p><strong>Quick exercise</strong> Repeat the above, but do it for Pct of Free Throws above .8.</p>
<pre class="r"><code>gms_ft_80_rs&lt;-NULL ##  Create a NULL variable: will fill this in later
for (i in 1:1000){ # Repeat the steps below 10,000 times
  gms_ft_80_rs&lt;-gms%&gt;% ## Create a dataset called gms_tov_rs (rs=resampled)
  filter(...)%&gt;%  ## Just 2017
  sample_n(...) %&gt;% ## Sample 100 games
  group_by(...)%&gt;% ## Group by won or lost
  summarize(...)%&gt;% ## Calculate mean turnovers for winners and losers
    bind_rows(...) ## add this result to the existing dataset
}</code></pre>
<pre><code>## Error in gms %&gt;% filter(...) %&gt;% sample_n(...) %&gt;% group_by(...) %&gt;% summarize(...) %&gt;% : &#39;...&#39; used in an incorrect context</code></pre>
</div>
<div id="distribution-of-resampled-means" class="section level2">
<h2>Distribution of Resampled Means</h2>
<p>That’s fine, but the other thing is that the <em>distribution</em> of those repeated samples will tell us about what we can expect to see in other, out of sample data that’s generated by the same process.</p>
<p>Let’s take a look at the distribution of turnovers for game winners:</p>
<pre class="r"><code>gms_tov_rs%&gt;%
  filter(isWin)%&gt;%
  ggplot(aes(x=mean_tov,fill=isWin))+
  geom_density(alpha=.3)+
  geom_vline(xintercept =12.9)</code></pre>
<p><img src="/data-science-site/homeworks/psc4175_hw_8_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>We can see that the mean of this distribution is centered right on the mean of the actual data, and it goes from about 11 to about 15. This is different than the minimum and maximum of the overall sample, which goes from 3 to 24 (bad night).</p>
<pre class="r"><code>gms_tov_rs%&gt;%
  filter(isWin)%&gt;%
  summarize(value=fivenum(mean_tov))%&gt;%
    mutate(measure=c(&quot;Min&quot;,&quot;25th percentile&quot;,&quot;Median&quot;,&quot;75th percentile&quot;,&quot;Max&quot;))%&gt;%
  select(measure, value)</code></pre>
<pre><code>## # A tibble: 5 × 2
##   measure         value
##   &lt;chr&gt;           &lt;dbl&gt;
## 1 Min              11.4
## 2 25th percentile  12.6
## 3 Median           13.0
## 4 75th percentile  13.3
## 5 Max              14.5</code></pre>
<p>So what this tells us is that the minimum turnovers for winners in all of the samples we drew was 11.4, the maximum was about 14.5 and the median was 13.0.</p>
<p>And for game losers, let’s look at the distribution.</p>
<pre class="r"><code>gms_tov_rs%&gt;%
  filter(!isWin)%&gt;%
  ggplot(aes(x=mean_tov,fill=isWin))+
  geom_density(alpha=.3,fill=&quot;lightblue&quot;)+
    geom_vline(xintercept =13.8)</code></pre>
<p><img src="/data-science-site/homeworks/psc4175_hw_8_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>And now the particular values.</p>
<pre class="r"><code>gms_tov_rs%&gt;%
  filter(!isWin)%&gt;%
  summarize(value=fivenum(mean_tov))%&gt;%
    mutate(measure=c(&quot;Min&quot;,&quot;25th percentile&quot;,&quot;Median&quot;,&quot;75th percentile&quot;,&quot;Max&quot;))%&gt;%
  select(measure, value)</code></pre>
<pre><code>## # A tibble: 5 × 2
##   measure         value
##   &lt;chr&gt;           &lt;dbl&gt;
## 1 Min              12.3
## 2 25th percentile  13.5
## 3 Median           13.8
## 4 75th percentile  14.2
## 5 Max              15.9</code></pre>
<p>For game losers, minimum turnovers for winners in all of the samples we drew was 12.3, the maximum was about 16 (!!) and the median was 13.8.</p>
<p><strong>Quick exercise</strong> Calculate the same summary, but do it for Pct of Free Throws above .8.</p>
<pre class="r"><code>gms_ft_80_rs%&gt;%
  filter(isWin)%&gt;% # for those who won
  summarize(value=fivenum(mean_ft80))%&gt;% ## Five number summary: described below
  mutate(measure=c(&quot;Min&quot;,&quot;25th percentile&quot;,&quot;Median&quot;,&quot;75th percentile&quot;,&quot;Max&quot;))%&gt;%
  select(measure, value)</code></pre>
<pre><code>## Error in UseMethod(&quot;filter&quot;): no applicable method for &#39;filter&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<pre class="r"><code>gms_ft_80_rs%&gt;% # now do the same for losers
  filter(...)%&gt;%
  summarize(...)%&gt;% ## Five number summary: described below
  mutate(...)%&gt;%
  select(...)</code></pre>
<pre><code>## Error in gms_ft_80_rs %&gt;% filter(...) %&gt;% summarize(...) %&gt;% mutate(...) %&gt;% : &#39;...&#39; used in an incorrect context</code></pre>
</div>
<div id="so-what-using-percentiles-of-the-resampled-distribution" class="section level2">
<h2>So What? Using Percentiles of the Resampled Distribution</h2>
<p>Now we can make some statements about uncertainty. Based on this what we can say is that in other seasons, we would expect that turnover for game winners will be in a certain range, and the same for game losers. What range? Well it depends on the level of risk you’re willing to take as an analyst. Academics (a cautious bunch to be sure) usually use the 5th percentile and the 95th percentile of the resampled values that were created.</p>
<p>So for game winners:</p>
<pre class="r"><code>gms_tov_rs%&gt;%
  filter(isWin)%&gt;%
  summarize(pct_025=quantile(mean_tov,.025),
            pct_975=quantile(mean_tov,.975))</code></pre>
<pre><code>## # A tibble: 1 × 2
##   pct_025 pct_975
##     &lt;dbl&gt;   &lt;dbl&gt;
## 1      12    14.0</code></pre>
<p>This tells us we can expect that game winners in future seasons will turn the ball over between about 12 and 14 times.</p>
<p>And how many times will their free throw percentage exceed 80%?</p>
<pre class="r"><code>gms_ft_80_rs%&gt;%
  filter(isWin)%&gt;%
  summarize(pct_025=quantile(mean_ft80,.025),
            pct_975=quantile(mean_ft80,.975))</code></pre>
<pre><code>## Error in UseMethod(&quot;filter&quot;): no applicable method for &#39;filter&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<p>And for game losers</p>
<pre class="r"><code>gms_tov_rs%&gt;%
  filter(!isWin)%&gt;%
  summarize(pct_05=quantile(mean_tov,.025),
            pct_95=quantile(mean_tov,.975))</code></pre>
<pre><code>## # A tibble: 1 × 2
##   pct_05 pct_95
##    &lt;dbl&gt;  &lt;dbl&gt;
## 1   12.8   14.9</code></pre>
<p>This tells us that we can expect that game losers in future seasons will turn the ball over between … 12.8 and 14.9 times.</p>
<p>Don’t be disappointed! It just turns out that if we want to make accurate statements about out of sample data, we need to reflect our uncertainty.</p>
<p>Let’s check to see if our expectations are borne out in future seasons:</p>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2018)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        14.1
## 2 TRUE         13.3</code></pre>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2019)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        13.9
## 2 TRUE         13.1</code></pre>
<p>So, our intervals for both winners and losers did include the values in future seasons.</p>
</div>
<div id="other-intervals-the-tradeoff-between-a-precise-interval-and-risk" class="section level2">
<h2>Other intervals– the tradeoff between a “precise” interval and risk</h2>
<p>You may be underwhelmed at this point, because the 95 percent range is a big range of possible turnover values. We can use narrower intervals– it just raises the risk of being wrong. Let’s try the middle 50 percent.</p>
<pre class="r"><code>gms_tov_rs%&gt;%
  group_by(isWin)%&gt;%
  summarize(pct_25=quantile(mean_tov,.25),
            pct_75=quantile(mean_tov,.75))</code></pre>
<pre><code>## # A tibble: 2 × 3
##   isWin pct_25 pct_75
##   &lt;lgl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 FALSE   13.5   14.2
## 2 TRUE    12.6   13.3</code></pre>
<p>Okay, now we’re saying that winners will have between 12.6 and 13.3 turnovers. Is that right?</p>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2018)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        14.1
## 2 TRUE         13.3</code></pre>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2019)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        13.9
## 2 TRUE         13.1</code></pre>
<p>Yes, this checks out for subsequent seasons. What about a really narrow interval– the middle 10 percent?</p>
<pre class="r"><code>gms_tov_rs%&gt;%
  group_by(isWin)%&gt;%
  summarize(pct_45=quantile(mean_tov,.45),
            pct_55=quantile(mean_tov,.55))</code></pre>
<pre><code>## # A tibble: 2 × 3
##   isWin pct_45 pct_55
##   &lt;lgl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 FALSE   13.8   13.9
## 2 TRUE    12.9   13.0</code></pre>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2018)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        14.1
## 2 TRUE         13.3</code></pre>
<p>In 2018, winning teams turned the ball over 13.3 times, on average. That’s below the range we gave! If we used a 10 percent interval we’d be wrong. Similarly, in 2018 losing teams turned the ball over 14.1 times, again below our interval.</p>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2019)%&gt;%
  group_by(isWin)%&gt;%
  summarize(mean(tov))</code></pre>
<pre><code>## # A tibble: 2 × 2
##   isWin `mean(tov)`
##   &lt;lgl&gt;       &lt;dbl&gt;
## 1 FALSE        13.9
## 2 TRUE         13.1</code></pre>
<p>In 2019, winning teams turned the ball over 13.1 times, on average. That’s below the range we gave! If we used a 10 percent interval we’d be wrong, again.</p>
<p>It turns out that the way this method works is that for an interval of a certain range, the calculated interval will include the true value of the measure in the same percent <em>of repeated samples</em>. We can think of each season as a repeated sample, so the middle 95 percent of this range will include the true value in 95 percent of seasons. When we call this a confidence interval, we’re saying we have confidence in the approach, not the particular values we calculated.</p>
<p>The tradeoff here is between providing a narrow range of values vs. the probability of being correct. We can give a very narrow interval for what we would expect to see in out of sample data, but we’re going to be wrong– a lot. We can give a very wide interval, but the information isn’t going to be useful to decisionmakers. This is one of the key tradeoffs in applied data analysis, and there’s no single answer to the question: what interval should I use? Academic work has settled on the 95 percent interval, but there’s no real theoretical justification for this.</p>
</div>
<div id="empirical-bootstrap" class="section level2">
<h2>Empirical Bootstrap</h2>
<p>What we just did is called the <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading24.pdf">empirical bootstrap</a>. It’s massively useful, because it can be applied for any summary measure of the data: median, percentiles, and measures like regression coefficients. Here is the summary of steps for the empirical bootstrap:</p>
<ul>
<li>Decide on the summary measure to be used for the variable (it doesn’t have to be the mean)</li>
<li>Calculate the summary measure on a small subsample (called the bootstrap sample) of the data</li>
<li>Repeat step 2 many times (how many? Start with 1000, but more is better.) Compile the estimates.</li>
<li>Calculate the percentiles of the bootstrap distribution from the previous step.</li>
<li>Describe your uncertainty using those percentiles.</li>
</ul>
<p><strong>Quick exercise</strong> Does 50 percent interval for free throws percent above 80 include the values for subsequent seasons?</p>
<pre class="r"><code>gms_ft_80_rs%&gt;%
  group_by(...)%&gt;%
  summarize(pct_25=quantile(...),
           pct_75=quantile(...))</code></pre>
<pre><code>## Error in summarize(., pct_25 = quantile(...), pct_75 = quantile(...)): &#39;...&#39; used in an incorrect context</code></pre>
<p>The middle 50% of this distribution is between .36 and .46.</p>
<p>And in the actual subsequent seasons</p>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2018)%&gt;%
  summarize(mean(ft_80))</code></pre>
<pre><code>## # A tibble: 1 × 1
##   `mean(ft_80)`
##           &lt;dbl&gt;
## 1         0.389</code></pre>
<p>Yep, that checks out. And in 2019?</p>
<pre class="r"><code>gms%&gt;%
  filter(yearSeason==2019)%&gt;%
  summarize(mean(ft_80))</code></pre>
<pre><code>## # A tibble: 1 × 1
##   `mean(ft_80)`
##           &lt;dbl&gt;
## 1         0.368</code></pre>
<p>Again, yes but just barely.</p>
</div>
<div id="summarizing-the-bootstrap" class="section level1">
<h1>Summarizing the Bootstrap</h1>
<p>The goal is to repeatedly calculate a measure of interest on random samples of the data. There are two basic ways to do this, both of which use a loop.</p>
<ol style="list-style-type: decimal">
<li>Use a loop to generate 100 (or 1,000, or more) simulated datasets and then run the analysis on this massive object.</li>
<li>Use a loop to generate a single simulated dataset and run the analysis within the loop, saving only the measures of interest.</li>
</ol>
<p>To demonstrate, we’re going to go back to the other NBA data.</p>
<pre class="r"><code>nba &lt;- readRDS(&#39;../data/nba_players_2018.Rds&#39;)</code></pre>
<pre><code>## Error in gzfile(file, &quot;rb&quot;): cannot open the connection</code></pre>
<p>We want to know if players from Tennessee are better at shooting free throws than players from Virginia. If we look at the overall data, we can see that NBA players who graduated from Tennessee are better overall.</p>
<pre class="r"><code>nba %&gt;%
  filter(org %in% c(&#39;Tennessee&#39;,&#39;Virginia&#39;)) %&gt;%
  group_by(org) %&gt;%
  summarise(pctFT = mean(pctFT))</code></pre>
<pre><code>## Error: object &#39;nba&#39; not found</code></pre>
<p>So now let’s bootstrap this to express how <strong>confident</strong> we are in this conclusion.</p>
</div>
<div id="method-1-big-dataset" class="section level1">
<h1>Method 1: Big Dataset</h1>
<pre class="r"><code>set.seed(123)
bsSeasons &lt;- NULL
for(bsSeason in 1:100) {
  tmpSeason &lt;- nba %&gt;%
    sample_n(size = nrow(.),replace = T) %&gt;%
    select(org,pctFT) %&gt;%
    mutate(bsSeasonNumber = bsSeason)
  bsSeasons &lt;- bind_rows(bsSeasons,tmpSeason)
}</code></pre>
<pre><code>## Error: object &#39;nba&#39; not found</code></pre>
<pre class="r"><code>nrow(bsSeasons)</code></pre>
<pre><code>## NULL</code></pre>
<p>We have a huge dataset of 100 simulated seasons which we can now run our analysis on. First, let’s compare free throw shooting in each simulated season.</p>
<pre class="r"><code>bsSeasons %&gt;%
  filter(grepl(&#39;Tennessee|^Virginia&#39;,org)) %&gt;% # Focus only on the schools of interest
  group_by(bsSeasonNumber,org) %&gt;% # Group by the simulated season and the organization
  summarise(mean_ftp = mean(pctFT),.groups = &#39;drop&#39;) # Calculate average pctFT</code></pre>
<pre><code>## Error in UseMethod(&quot;filter&quot;): no applicable method for &#39;filter&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<p>In simulated seasons 1, 2, and 5 Tennessee grads are better shooters. However, in simulated seasons 3 and 4, Virginia grads have a better percentage!</p>
<p>But remember the question of interest – we want to calculate the <em>difference</em> in free throw percentage. To do this, we can use the <code>spread()</code> command to create one column for Tennessee and one column for Virginia</p>
<pre class="r"><code>bsSeasons %&gt;%
  filter(grepl(&#39;Tennessee|^Virginia&#39;,org)) %&gt;%
  group_by(bsSeasonNumber,org) %&gt;%
  summarise(mean_ftp = mean(pctFT),.groups = &#39;drop&#39;) %&gt;%
  spread(org,mean_ftp) # Create two columns one for each school</code></pre>
<pre><code>## Error in UseMethod(&quot;filter&quot;): no applicable method for &#39;filter&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<p>Interestingly, in seasons 7 and 8 we **don’t have measures of Virginia free throw shooting! This is because we just happened not to sample any players from Virginia in these simulated seasons! We can drop these missing values and then use <code>mutate()</code> to create the difference between Virginia and Tennessee.</p>
<pre class="r"><code>bsSeasons %&gt;%
  filter(grepl(&#39;Tennessee|^Virginia&#39;,org)) %&gt;%
  group_by(bsSeasonNumber,org) %&gt;%
  summarise(mean_ftp = mean(pctFT),.groups = &#39;drop&#39;) %&gt;%
  spread(org,mean_ftp) %&gt;%
  drop_na() %&gt;% # Drop any rows with missing data in any column
  mutate(TNDiff = Tennessee - Virginia) # Calculate the difference in free throw shooting between TN and VA</code></pre>
<pre><code>## Error in UseMethod(&quot;filter&quot;): no applicable method for &#39;filter&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<p>Values that are greater than zero indicate simulated seasons where Tennessee grads shot better, while values less than zero indicate simulated seasons where Virginia grads shot better. We can plot this as a distribution!</p>
<pre class="r"><code>bsSeasons %&gt;%
  filter(grepl(&#39;Tennessee|^Virginia&#39;,org)) %&gt;%
  group_by(bsSeasonNumber,org) %&gt;%
  summarise(mean_ftp = mean(pctFT),.groups = &#39;drop&#39;) %&gt;%
  spread(org,mean_ftp) %&gt;%
  drop_na() %&gt;%
  mutate(TNDiff = Tennessee - Virginia) %&gt;%
  ggplot(aes(x = TNDiff)) + # Plot the difference
  geom_density() + 
  geom_vline(xintercept = 0,linetype = &#39;dashed&#39;) # Add a vertical line for clarity</code></pre>
<pre><code>## Error in UseMethod(&quot;filter&quot;): no applicable method for &#39;filter&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<p>Our confidence is the proportion of times that Tennessee outshoots Virginia grads, or the proportion of the data that is to the <strong>right</strong> of zero (indicated with the vertical dashed line). We can calculate this proportion directly with a mean!</p>
<pre class="r"><code>bsSeasons %&gt;%
  filter(grepl(&#39;Tennessee|^Virginia&#39;,org)) %&gt;%
  group_by(bsSeasonNumber,org) %&gt;%
  summarise(mean_ftp = mean(pctFT),.groups = &#39;drop&#39;) %&gt;%
  spread(org,mean_ftp) %&gt;%
  drop_na() %&gt;%
  mutate(TNDiff = Tennessee - Virginia) %&gt;%
  mutate(TNBetter = ifelse(TNDiff &gt; 0,1,0)) %&gt;% # Create an indicator for whether TN did better
  summarise(mean(TNBetter))</code></pre>
<pre><code>## Error in UseMethod(&quot;filter&quot;): no applicable method for &#39;filter&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<p>The benefit of creating the huge dataset first and then analyzing it is that we can look at many different aspects of the data. We can calculate the overall confidence, or we can plot the distribution of the difference. We can even plot the two distributions for each school!</p>
<pre class="r"><code>bsSeasons %&gt;%
  filter(grepl(&#39;Tennessee|^Virginia&#39;,org)) %&gt;%
  group_by(bsSeasonNumber,org) %&gt;%
  summarise(mean_ftp = mean(pctFT),.groups = &#39;drop&#39;) %&gt;%
  ggplot(aes(x = mean_ftp,fill = org)) + # Plot the difference
  geom_density(alpha = .3)</code></pre>
<pre><code>## Error in UseMethod(&quot;filter&quot;): no applicable method for &#39;filter&#39; applied to an object of class &quot;NULL&quot;</code></pre>
</div>
<div id="method-2-calculate-within-the-loop" class="section level1">
<h1>Method 2: Calculate within the loop</h1>
<p>We could have instead calculated all this WITHIN each loop of the bootstrap.</p>
<pre class="r"><code>set.seed(123)
bsRes &lt;- NULL
for(counter in 1:100) {
  tmpEst &lt;- nba %&gt;%
    sample_n(size = nrow(.),replace = T) %&gt;%
    filter(org %in% c(&#39;Tennessee&#39;,&#39;Virginia&#39;)) %&gt;%
    group_by(org) %&gt;%
    summarise(mean_FT = mean(pctFT,na.rm=T)) %&gt;%
    ungroup() %&gt;%
    spread(org,mean_FT) %&gt;%
    mutate(bsSeason = counter)
  bsRes &lt;- bind_rows(bsRes,tmpEst)
}</code></pre>
<pre><code>## Error: object &#39;nba&#39; not found</code></pre>
<p>Then we can plot and calculate without having to do the analysis.</p>
<pre class="r"><code>bsRes %&gt;%
  drop_na() %&gt;%
  summarise(mean(Tennessee &gt; Virginia)) # NOTE: You can calculate the average of TRUE/FALSE logic and R will know to treat it as a 1/0 number.</code></pre>
<pre><code>## Error in UseMethod(&quot;drop_na&quot;): no applicable method for &#39;drop_na&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<pre class="r"><code>bsRes %&gt;%
  drop_na() %&gt;%
  mutate(TNDiff = Tennessee - Virginia) %&gt;%
  ggplot(aes(x = TNDiff)) + 
  geom_density() + 
  geom_vline(xintercept = 0,linetype = &#39;dashed&#39;)</code></pre>
<pre><code>## Error in UseMethod(&quot;drop_na&quot;): no applicable method for &#39;drop_na&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<p>We can use the <code>gather()</code> command to get the overlapping plot as well.</p>
<pre class="r"><code>bsRes %&gt;%
  drop_na() %&gt;%
  gather(org,mean_ft,-bsSeason) %&gt;%
  ggplot(aes(x = mean_ft,fill = org)) + 
  geom_density(alpha = .3)</code></pre>
<pre><code>## Error in UseMethod(&quot;drop_na&quot;): no applicable method for &#39;drop_na&#39; applied to an object of class &quot;NULL&quot;</code></pre>
<p><strong>Quick exercise</strong> Which team has the highest free throw percentage? How confident are you?</p>
<pre class="r"><code># INSERT CODE HERE</code></pre>
</div>
